# RAGé“¾è·¯è°ƒè¯•ç³»ç»Ÿ - ä½¿ç”¨è¯´æ˜

## ğŸ¯ åŠŸèƒ½æ¦‚è¿°

æœ¬ç³»ç»Ÿæä¾›å®Œæ•´çš„RAGé“¾è·¯å¯è§†åŒ–è°ƒè¯•å·¥å…·ï¼Œè®©æ¯ä¸ªç¯èŠ‚éƒ½èƒ½ç‹¬ç«‹æµ‹è¯•å’ŒéªŒè¯ã€‚

---

## ğŸ“¦ å®‰è£…ä¾èµ–

### åç«¯ä¾èµ–

```bash
cd backend
source .venv/bin/activate

# åŸºç¡€ä¾èµ–ï¼ˆå·²å®‰è£…ï¼‰
pip install fastapi uvicorn pydantic

# æ–°å¢ä¾èµ–
pip install jieba          # ä¸­æ–‡åˆ†è¯
pip install PyPDF2         # PDFè§£æï¼ˆå¯é€‰ï¼‰
pip install python-docx    # DOCXè§£æï¼ˆå¯é€‰ï¼‰
pip install numpy          # å‘é‡è®¡ç®—
```

### å‰ç«¯ä¾èµ–

å·²åŒ…å«åœ¨é¡¹ç›®ä¸­ï¼Œæ— éœ€é¢å¤–å®‰è£…ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¯åŠ¨åç«¯

```bash
cd backend
source .venv/bin/activate
python run.py
```

åç«¯APIåœ°å€: `http://localhost:8000`

### 2. å¯åŠ¨å‰ç«¯

```bash
cd web
npm run dev
```

å‰ç«¯åœ°å€: `http://localhost:3000`

### 3. è®¿é—®é“¾è·¯è°ƒè¯•é¡µé¢

åœ¨æµè§ˆå™¨ä¸­è®¿é—®: `http://localhost:3000/pipeline-debug`
ï¼ˆéœ€è¦åœ¨ä¾§è¾¹æ æ·»åŠ å…¥å£ï¼‰

---

## ğŸ”§ ä½¿ç”¨æµç¨‹

### æ­¥éª¤1: æ–‡æ¡£å¤„ç†

**åŠŸèƒ½:**
- ä¸Šä¼ æ–‡æ¡£ï¼ˆTXT, MD, PDF, DOCXï¼‰
- è§£ææ–‡æ¡£å†…å®¹
- æ–‡æ¡£åˆ†å—

**æ“ä½œæ­¥éª¤:**
1. ç‚¹å‡»"é€‰æ‹©æ–‡ä»¶"ä¸Šä¼ æ–‡æ¡£
2. ç‚¹å‡»"ä¸Šä¼ å¹¶è§£æ"
3. æŸ¥çœ‹è§£æåçš„æ–‡æœ¬ï¼ˆå¯æ‰‹åŠ¨ç¼–è¾‘ï¼‰
4. ç‚¹å‡»"å¼€å§‹åˆ†å—"
5. æŸ¥çœ‹åˆ†å—ç»“æœåˆ—è¡¨

**åˆ†å—å‚æ•°:**
- `chunk_size`: åˆ†å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰ï¼Œé»˜è®¤500
- `chunk_overlap`: é‡å å¤§å°ï¼Œé»˜è®¤50
- `method`: åˆ†å—æ–¹æ³•ï¼ˆfixed_size/paragraph/sentenceï¼‰

**ç¤ºä¾‹è¾“å‡º:**
```json
{
  "chunks": [
    {
      "index": 0,
      "content": "è¿™æ˜¯ç¬¬ä¸€ä¸ªåˆ†å—çš„å†…å®¹...",
      "char_count": 485,
      "start_pos": 0,
      "end_pos": 485
    }
  ],
  "statistics": {
    "total_chunks": 15,
    "avg_chunk_size": 492.3
  }
}
```

---

### æ­¥éª¤2: æ–‡æ¡£å‘é‡åŒ–

**åŠŸèƒ½:**
- æ‰¹é‡å‘é‡åŒ–åˆ†å—
- é¢„è§ˆå‘é‡ç»“æœ
- æ˜¾ç¤ºå‘é‡ç»´åº¦

**æ“ä½œæ­¥éª¤:**
1. ç‚¹å‡»"å¼€å§‹å‘é‡åŒ–"
2. ç­‰å¾…å¤„ç†å®Œæˆ
3. æŸ¥çœ‹å‘é‡é¢„è§ˆï¼ˆå‰5ç»´ï¼‰

**ä½¿ç”¨æ¨¡å‹:**
- `bge-m3:latest` (1024ç»´)
- `nomic-embed-text:latest` (768ç»´)

**æ³¨æ„äº‹é¡¹:**
- ç¡®ä¿OllamaæœåŠ¡å·²å¯åŠ¨
- ç¡®ä¿æ¨¡å‹å·²ä¸‹è½½: `ollama pull bge-m3`

**ç¤ºä¾‹è¾“å‡º:**
```json
{
  "preview": [
    {
      "index": 0,
      "dimension": 1024,
      "preview": [0.234, -0.156, 0.891, 0.045, -0.321],
      "norm": 1.0
    }
  ]
}
```

---

### æ­¥éª¤3: æ–‡æ¡£åˆ†è¯

**åŠŸèƒ½:**
- ä½¿ç”¨jiebaè¿›è¡Œä¸­æ–‡åˆ†è¯
- è¿‡æ»¤åœç”¨è¯
- ç»Ÿè®¡è¯é¢‘

**æ“ä½œæ­¥éª¤:**
1. ç‚¹å‡»"å¼€å§‹åˆ†è¯"
2. æŸ¥çœ‹åˆ†è¯ç»“æœé¢„è§ˆ
3. æŸ¥çœ‹è¯é¢‘ç»Ÿè®¡ï¼ˆTop 20ï¼‰

**åˆ†è¯æ¨¡å¼:**
- `default`: ç²¾ç¡®æ¨¡å¼
- `search`: æœç´¢å¼•æ“æ¨¡å¼ï¼ˆæ¨èï¼‰
- `all`: å…¨æ¨¡å¼

**ç¤ºä¾‹è¾“å‡º:**
```json
{
  "preview": [
    {
      "index": 0,
      "original": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯",
      "tokens": ["æœºå™¨å­¦ä¹ ", "äººå·¥æ™ºèƒ½", "é‡è¦", "åˆ†æ”¯"],
      "token_count": 4
    }
  ],
  "statistics": {
    "total_tokens": 150,
    "unique_tokens": 85,
    "top_words": [
      {"word": "æœºå™¨å­¦ä¹ ", "freq": 15},
      {"word": "äººå·¥æ™ºèƒ½", "freq": 12}
    ]
  }
}
```

---

### æ­¥éª¤4: ç´¢å¼•å†™å…¥

**åŠŸèƒ½:**
- å†™å…¥å‘é‡ç´¢å¼•åˆ°å‘é‡æ•°æ®åº“
- å†™å…¥å…³é”®è¯ç´¢å¼•åˆ°å€’æ’ç´¢å¼•
- éªŒè¯ç´¢å¼•å®Œæ•´æ€§

**æ“ä½œæ­¥éª¤:**
1. ç¡®ä¿å·²å®Œæˆå‘é‡åŒ–å’Œåˆ†è¯
2. ç‚¹å‡»"å†™å…¥ç´¢å¼•"
3. ç­‰å¾…å†™å…¥å®Œæˆ
4. æŸ¥çœ‹å†™å…¥ç»Ÿè®¡

**çŠ¶æ€è¯´æ˜:**
- âš ï¸ **å½“å‰çŠ¶æ€:** å¾…å®ç°
- éœ€è¦å®ç°å‘é‡DBè¿æ¥å’Œå€’æ’ç´¢å¼•æ„å»º

**é¢„æœŸè¾“å‡º:**
```json
{
  "vector": {
    "written_count": 15,
    "kb_id": "kb_demo"
  },
  "keyword": {
    "written_count": 15,
    "unique_tokens": 125
  }
}
```

---

### æ­¥éª¤5: æ£€ç´¢æµ‹è¯•

**åŠŸèƒ½:**
- å‘é‡æ£€ç´¢
- å…³é”®è¯æ£€ç´¢
- æ··åˆæ£€ç´¢ï¼ˆRRFèåˆï¼‰

**æ“ä½œæ­¥éª¤:**
1. è¾“å…¥æŸ¥è¯¢æ–‡æœ¬
2. é€‰æ‹©æ£€ç´¢æ¨¡å¼
3. è°ƒæ•´å‚æ•°
4. ç‚¹å‡»"æ‰§è¡Œæ£€ç´¢"
5. æŸ¥çœ‹ç»“æœåˆ—è¡¨

**æ£€ç´¢å‚æ•°:**
- `top_k`: è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤5
- `vector_weight`: å‘é‡æ£€ç´¢æƒé‡ï¼Œé»˜è®¤0.7
- `keyword_weight`: å…³é”®è¯æ£€ç´¢æƒé‡ï¼Œé»˜è®¤0.3
- `rrf_k`: RRFèåˆå‚æ•°ï¼Œé»˜è®¤60

**RRFç®—æ³•è¯´æ˜:**
```
RRFåˆ†æ•° = 1 / (k + rank)

èåˆå¤šä¸ªæ£€ç´¢ç»“æœ:
final_score = sum(weight_i * rrf_score_i)
```

**ç¤ºä¾‹è¾“å‡º:**
```json
{
  "query": "æœºå™¨å­¦ä¹ çš„åº”ç”¨",
  "query_tokens": ["æœºå™¨å­¦ä¹ ", "åº”ç”¨"],
  "results": [
    {
      "rank": 1,
      "chunk_id": "chunk_5",
      "content": "æœºå™¨å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«é¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨...",
      "score": 0.91,
      "source": "hybrid"
    }
  ]
}
```

---

## ğŸ§ª APIæµ‹è¯•

### ä½¿ç”¨curlæµ‹è¯•

#### 1. æ–‡æ¡£åˆ†å—

```bash
curl -X POST "http://localhost:8000/api/v1/debug/document/chunk" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬ã€‚éœ€è¦è¿›è¡Œåˆ†å—å¤„ç†ã€‚",
    "method": "fixed_size",
    "chunk_size": 20,
    "chunk_overlap": 5
  }'
```

#### 2. jiebaåˆ†è¯

```bash
curl -X POST "http://localhost:8000/api/v1/debug/tokenize/jieba" \
  -H "Content-Type: application/json" \
  -d '{
    "texts": ["æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯"],
    "mode": "search",
    "use_stop_words": true
  }'
```

#### 3. RRFæµ‹è¯•

```bash
curl -X POST "http://localhost:8000/api/v1/debug/test/rrf" \
  -H "Content-Type: application/json" \
  -d '{
    "results_lists": [
      [
        {"chunk_id": "doc1", "score": 0.9, "rank": 1},
        {"chunk_id": "doc2", "score": 0.8, "rank": 2}
      ],
      [
        {"chunk_id": "doc2", "score": 0.85, "rank": 1},
        {"chunk_id": "doc3", "score": 0.75, "rank": 2}
      ]
    ],
    "k": 60,
    "weights": [0.7, 0.3]
  }'
```

---

## ğŸ“Š å®Œæ•´ç¤ºä¾‹æµç¨‹

### æµ‹è¯•æ–‡æ¡£

åˆ›å»º `test.txt`:
```
æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯ï¼Œå®ƒä½¿è®¡ç®—æœºç³»ç»Ÿèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ å’Œæ”¹è¿›ã€‚
æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¥å¤„ç†å¤æ‚çš„æ¨¡å¼è¯†åˆ«ä»»åŠ¡ã€‚
å¸¸è§çš„æœºå™¨å­¦ä¹ ç®—æ³•åŒ…æ‹¬å†³ç­–æ ‘ã€æ”¯æŒå‘é‡æœºã€éšæœºæ£®æ—ç­‰ã€‚
```

### å®Œæ•´æµç¨‹

1. **ä¸Šä¼ æ–‡æ¡£** â†’ è·å– `temp_path`
2. **è§£ææ–‡æ¡£** â†’ è·å–æ–‡æœ¬å†…å®¹
3. **åˆ†å—** (chunk_size=100, overlap=20) â†’ è·å–3ä¸ªåˆ†å—
4. **å‘é‡åŒ–** (bge-m3) â†’ è·å–3ä¸ª1024ç»´å‘é‡
5. **åˆ†è¯** (jieba searchæ¨¡å¼) â†’ è·å–åˆ†è¯åˆ—è¡¨
6. **ç´¢å¼•å†™å…¥** â†’ å†™å…¥å‘é‡DBå’Œå€’æ’ç´¢å¼•
7. **æ£€ç´¢æµ‹è¯•** (æŸ¥è¯¢: "æœºå™¨å­¦ä¹ ç®—æ³•") â†’ è·å–ç›¸å…³ç»“æœ

---

## âš™ï¸ é…ç½®è¯´æ˜

### åˆ†å—é…ç½®

```python
# backend/app/services/document_processor.py

CHUNK_CONFIG = {
    "fixed_size": {
        "chunk_size": 500,      # å­—ç¬¦æ•°
        "chunk_overlap": 50,    # é‡å å­—ç¬¦æ•°
    },
    "paragraph": {},            # æŒ‰æ®µè½åˆ†å—
    "sentence": {
        "max_sentences": 5      # æ¯å—æœ€å¤šå¥å­æ•°
    }
}
```

### Embeddingé…ç½®

```python
# å¯ç”¨æ¨¡å‹
EMBEDDING_MODELS = {
    "bge-m3:latest": 1024,          # ä¸­æ–‡æœ€ä¼˜
    "nomic-embed-text:latest": 768   # è‹±æ–‡
}
```

### åˆ†è¯é…ç½®

```python
# backend/app/services/tokenizer_service.py

TOKENIZE_CONFIG = {
    "mode": "search",           # default/search/all
    "use_stop_words": True,     # æ˜¯å¦è¿‡æ»¤åœç”¨è¯
}

# å¯ä»¥æ·»åŠ è‡ªå®šä¹‰åœç”¨è¯
tokenizer.add_stop_words(["è‡ªå®šä¹‰è¯1", "è‡ªå®šä¹‰è¯2"])
```

### RRFé…ç½®

```python
RRF_CONFIG = {
    "k": 60,                    # RRFå‚æ•°ï¼ˆé€šå¸¸60ï¼‰
    "vector_weight": 0.7,       # å‘é‡æ£€ç´¢æƒé‡
    "keyword_weight": 0.3       # å…³é”®è¯æ£€ç´¢æƒé‡
}
```

---

## ğŸ› æ•…éšœæ’æŸ¥

### 1. jiebaæœªå®‰è£…

**é”™è¯¯:** `ImportError: No module named 'jieba'`

**è§£å†³:**
```bash
pip install jieba
```

### 2. Ollamaè¿æ¥å¤±è´¥

**é”™è¯¯:** `Connection refused to localhost:11434`

**è§£å†³:**
```bash
# å¯åŠ¨Ollama
ollama serve

# ä¸‹è½½æ¨¡å‹
ollama pull bge-m3
```

### 3. PDFè§£æå¤±è´¥

**é”™è¯¯:** `No module named 'PyPDF2'`

**è§£å†³:**
```bash
pip install PyPDF2
```

### 4. å‘é‡ç»´åº¦ä¸åŒ¹é…

**é”™è¯¯:** `Dimension mismatch: 768 vs 1024`

**è§£å†³:** ç¡®ä¿ä½¿ç”¨ç›¸åŒçš„embeddingæ¨¡å‹

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡å‘é‡åŒ–ï¼ˆæ¨èï¼‰
batch_size = 50
for i in range(0, len(texts), batch_size):
    batch = texts[i:i+batch_size]
    vectors = await embed_batch(batch)
```

### 2. ç¼“å­˜æœºåˆ¶

```python
# ç¼“å­˜å‘é‡ç»“æœ
cache_key = f"embed:{text_hash}"
if cache_key in cache:
    return cache[cache_key]
```

### 3. å¼‚æ­¥å¤„ç†

```python
# å¹¶å‘å¤„ç†
async def process_all():
    tasks = [
        embed_text(text) for text in texts
    ]
    results = await asyncio.gather(*tasks)
```

---

## ğŸ“ å¼€å‘è¯´æ˜

### å¾…å®ç°åŠŸèƒ½

1. **å‘é‡ç´¢å¼•å†™å…¥** (æ­¥éª¤4)
   - ChromaDBé›†æˆ
   - Milvusé›†æˆ
   - ç´¢å¼•éªŒè¯

2. **å…³é”®è¯ç´¢å¼•å†™å…¥** (æ­¥éª¤4)
   - å€’æ’ç´¢å¼•æ„å»º
   - BM25è¯„åˆ†
   - æŒä¹…åŒ–å­˜å‚¨

3. **å®é™…æ£€ç´¢** (æ­¥éª¤5)
   - è¿æ¥å‘é‡DB
   - æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
   - å…³é”®è¯åŒ¹é…

### æ‰©å±•åŠŸèƒ½

1. **æ›´å¤šåˆ†è¯å·¥å…·**
   - pkuseg
   - LTP
   - HanLP

2. **æ›´å¤šEmbeddingæ¨¡å‹**
   - OpenAI Embeddings
   - HuggingFace Models

3. **æ›´å¤šRerankç®—æ³•**
   - CRR (Correlation-based Reranking)
   - LTR (Learning to Rank)

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **æ¶æ„è®¾è®¡:** `é“¾è·¯è°ƒè¯•ç³»ç»Ÿ_æ¶æ„è®¾è®¡.md`
- **APIæ–‡æ¡£:** è®¿é—® `http://localhost:8000/docs`
- **å®Œæ•´ç¤ºä¾‹:** `example_pipeline_debug.py`

---

**æœ€åæ›´æ–°:** 2025-11-07  
**ç‰ˆæœ¬:** v1.0  
**çŠ¶æ€:** æ ¸å¿ƒåŠŸèƒ½å·²å®ç°ï¼Œç´¢å¼•å†™å…¥å’Œå®é™…æ£€ç´¢å¾…å®Œå–„

