# æ£€ç´¢å™¨è¯„ä¼°ç³»ç»Ÿ - å¿«é€Ÿå¯åŠ¨æŒ‡å—

## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡ç¯å¢ƒ

```bash
cd /Users/yeruijian/Documents/project/rag-studio/rag-studio/backend

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate

# å®‰è£…ä¾èµ–ï¼ˆå¦‚æœè¿˜æ²¡å®‰è£…ï¼‰
pip install -r requirements.txt
```

### 2. è¿è¡Œæµ‹è¯•

```bash
# è¿è¡ŒåŠŸèƒ½æµ‹è¯•
python test_retriever_eval.py
```

**é¢„æœŸè¾“å‡º:**
```
ğŸš€ æ£€ç´¢å™¨è¯„ä¼°ç³»ç»Ÿæµ‹è¯•
âœ… T2Rankingæ•°æ®é›†åŠ è½½æµ‹è¯• - é€šè¿‡
âœ… æ£€ç´¢å™¨è¯„ä¼°åŠŸèƒ½æµ‹è¯• - é€šè¿‡
ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ£€ç´¢å™¨è¯„ä¼°ç³»ç»Ÿå·²å°±ç»ªã€‚
```

### 3. è¿è¡Œç¤ºä¾‹

```bash
# è¿è¡Œä½¿ç”¨ç¤ºä¾‹
python example_t2ranking_usage.py
```

**ä½ å°†çœ‹åˆ°:**
- æ•°æ®é›†åŠ è½½æ¼”ç¤º
- å•æŸ¥è¯¢è¯„ä¼°æ¼”ç¤º
- æ‰¹é‡è¯„ä¼°æ¼”ç¤º
- é…ç½®å¯¹æ¯”æ¼”ç¤º

### 4. å¯åŠ¨APIæœåŠ¡

```bash
# å¯åŠ¨åç«¯æœåŠ¡
python run.py
```

è®¿é—® API æ–‡æ¡£: http://localhost:8000/api/v1/docs

## ğŸ“Š å¿«é€Ÿè¯„ä¼°ç¤ºä¾‹

### Pythonä»£ç ç¤ºä¾‹

```python
from app.services.dataset_loader import DatasetService
from app.services.retriever_evaluation import RetrieverEvaluator

# 1. åŠ è½½æ•°æ®é›†ï¼ˆé‡‡æ ·100ä¸ªæŸ¥è¯¢ï¼‰
dataset = DatasetService.load_t2ranking(
    collection_path="/Users/yeruijian/Documents/çŸ¥è¯†åº“å¹³å°/dataset/T2Ranking/data/collection.tsv",
    queries_path="/Users/yeruijian/Documents/çŸ¥è¯†åº“å¹³å°/dataset/T2Ranking/data/queries.dev.tsv",
    qrels_path="/Users/yeruijian/Documents/çŸ¥è¯†åº“å¹³å°/dataset/T2Ranking/data/qrels.dev.tsv",
    max_queries=100
)

# 2. åˆ›å»ºè¯„ä¼°å™¨
evaluator = RetrieverEvaluator(top_k=10)

# 3. è¯„ä¼°æ£€ç´¢ç»“æœ
metrics = evaluator.evaluate_single_query(
    retrieved_doc_ids=["doc_1", "doc_2", "doc_5"],
    relevant_doc_ids=["doc_2", "doc_5", "doc_7"]
)

print(f"Precision: {metrics['precision']:.4f}")
print(f"Recall: {metrics['recall']:.4f}")
print(f"F1-Score: {metrics['f1_score']:.4f}")
print(f"NDCG: {metrics['ndcg']:.4f}")
```

### cURL APIç¤ºä¾‹

```bash
# 1. æŸ¥çœ‹æ•°æ®é›†ç»Ÿè®¡
curl -X GET "http://localhost:8000/api/v1/retriever-evaluation/dataset-statistics" \
  -G \
  --data-urlencode "collection_path=/Users/yeruijian/Documents/çŸ¥è¯†åº“å¹³å°/dataset/T2Ranking/data/collection.tsv" \
  --data-urlencode "queries_path=/Users/yeruijian/Documents/çŸ¥è¯†åº“å¹³å°/dataset/T2Ranking/data/queries.dev.tsv" \
  --data-urlencode "qrels_path=/Users/yeruijian/Documents/çŸ¥è¯†åº“å¹³å°/dataset/T2Ranking/data/qrels.dev.tsv" \
  --data-urlencode "max_queries=100"

# 2. å¯¼å…¥æ•°æ®é›†åˆ°çŸ¥è¯†åº“
curl -X POST "http://localhost:8000/api/v1/retriever-evaluation/import-t2ranking" \
  -H "Content-Type: application/json" \
  -d '{
    "kb_id": "kb_t2ranking",
    "test_set_name": "T2Rankingæµ‹è¯•é›†",
    "collection_path": "/Users/yeruijian/Documents/çŸ¥è¯†åº“å¹³å°/dataset/T2Ranking/data/collection.tsv",
    "queries_path": "/Users/yeruijian/Documents/çŸ¥è¯†åº“å¹³å°/dataset/T2Ranking/data/queries.dev.tsv",
    "qrels_path": "/Users/yeruijian/Documents/çŸ¥è¯†åº“å¹³å°/dataset/T2Ranking/data/qrels.dev.tsv",
    "max_queries": 100,
    "description": "ç”¨äºæ£€ç´¢å™¨è¯„ä¼°çš„T2Rankingæ•°æ®é›†"
  }'
```

## ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡è¯´æ˜

| æŒ‡æ ‡ | è¯´æ˜ | èŒƒå›´ | ä¼˜ç§€æ ‡å‡† |
|-----|------|------|---------|
| **Precision@K** | æ£€ç´¢ç»“æœä¸­ç›¸å…³æ–‡æ¡£çš„æ¯”ä¾‹ | 0-1 | > 0.7 |
| **Recall@K** | ç›¸å…³æ–‡æ¡£è¢«æ£€ç´¢åˆ°çš„æ¯”ä¾‹ | 0-1 | > 0.7 |
| **F1-Score** | ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡ | 0-1 | > 0.7 |
| **MRR** | ç¬¬ä¸€ä¸ªç›¸å…³æ–‡æ¡£çš„æ’åå€’æ•° | 0-1 | > 0.8 |
| **MAP** | æ‰€æœ‰ç›¸å…³æ–‡æ¡£ä½ç½®çš„å¹³å‡ç²¾åº¦ | 0-1 | > 0.7 |
| **NDCG** | è€ƒè™‘æ’åºä½ç½®çš„ç»¼åˆæŒ‡æ ‡ | 0-1 | > 0.8 |
| **Hit Rate** | è‡³å°‘æ£€ç´¢åˆ°ä¸€ä¸ªç›¸å…³æ–‡æ¡£çš„æ¯”ä¾‹ | 0-1 | > 0.9 |

## ğŸ¯ å…¸å‹ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: å¯¹æ¯”ä¸åŒå‘é‡æ•°æ®åº“

```python
# æµ‹è¯• Elasticsearch
evaluator_es = RetrieverEvaluator(top_k=10)
metrics_es = evaluator_es.evaluate_single_query(retrieved_es, relevant)

# æµ‹è¯• Qdrant  
evaluator_qdrant = RetrieverEvaluator(top_k=10)
metrics_qdrant = evaluator_qdrant.evaluate_single_query(retrieved_qdrant, relevant)

# å¯¹æ¯”ç»“æœ
print(f"Elasticsearch F1: {metrics_es['f1_score']:.4f}")
print(f"Qdrant F1: {metrics_qdrant['f1_score']:.4f}")
```

### åœºæ™¯2: è¯„ä¼°embeddingæ¨¡å‹

```python
# æµ‹è¯•ä¸åŒçš„embeddingæ¨¡å‹
models = ["nomic-embed-text", "bge-large-zh", "text-embedding-ada-002"]

for model in models:
    # ä½¿ç”¨è¯¥æ¨¡å‹è¿›è¡Œæ£€ç´¢
    retrieved = retrieve_with_model(query, model)
    
    # è¯„ä¼°ç»“æœ
    metrics = evaluator.evaluate_single_query(retrieved, relevant)
    print(f"{model}: F1={metrics['f1_score']:.4f}, NDCG={metrics['ndcg']:.4f}")
```

### åœºæ™¯3: ä¼˜åŒ–æ£€ç´¢å‚æ•°

```python
# æµ‹è¯•ä¸åŒçš„top_kå€¼
for k in [5, 10, 20, 50]:
    evaluator = RetrieverEvaluator(top_k=k)
    metrics = evaluator.evaluate_batch(test_results)
    
    print(f"top_k={k}: Recall={metrics['recall']:.4f}")
```

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. æ•°æ®é›†è§„æ¨¡é€‰æ‹©

```python
# åˆæ¬¡æµ‹è¯• - å¿«é€ŸéªŒè¯
max_queries = 50

# ä¸­ç­‰è§„æ¨¡æµ‹è¯• - å¯é è¯„ä¼°
max_queries = 100-200

# å®Œæ•´æµ‹è¯• - ç”Ÿäº§ç¯å¢ƒ
max_queries = 500+
```

### 2. è¯„ä¼°æµç¨‹

1. **Baselineå»ºç«‹** - ä½¿ç”¨ç®€å•é…ç½®å»ºç«‹åŸºå‡†
2. **å•å› ç´ æµ‹è¯•** - æ¯æ¬¡åªæ”¹å˜ä¸€ä¸ªå‚æ•°
3. **è®°å½•ç»“æœ** - ä¿å­˜æ¯æ¬¡è¯„ä¼°çš„é…ç½®å’ŒæŒ‡æ ‡
4. **å¯¹æ¯”åˆ†æ** - ä½¿ç”¨å›¾è¡¨å¯¹æ¯”ä¸åŒé…ç½®

### 3. æ€§èƒ½ä¼˜åŒ–

```python
# âœ… æ¨èï¼šä½¿ç”¨é‡‡æ ·
dataset = DatasetService.load_t2ranking(
    ...,
    max_queries=100,  # é™åˆ¶æŸ¥è¯¢æ•°é‡
    max_docs=None     # è‡ªåŠ¨ç¡®å®šç›¸å…³æ–‡æ¡£
)

# âŒ ä¸æ¨èï¼šåŠ è½½å®Œæ•´æ•°æ®é›†ï¼ˆé™¤éå¿…è¦ï¼‰
dataset = DatasetService.load_t2ranking(...)
```

## ğŸ› å¸¸è§é—®é¢˜

### Q1: æ•°æ®é›†æ–‡ä»¶æ‰¾ä¸åˆ°
**A:** æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿æœ‰è¯»å–æƒé™

### Q2: å†…å­˜ä¸è¶³
**A:** ä½¿ç”¨ `max_queries` å’Œ `max_docs` å‚æ•°è¿›è¡Œé‡‡æ ·

### Q3: è¯„ä¼°ç»“æœä¸ç†æƒ³
**A:** æ£€æŸ¥ä»¥ä¸‹æ–¹é¢ï¼š
- æ–‡æ¡£æ˜¯å¦æ­£ç¡®å‘é‡åŒ–
- embeddingæ¨¡å‹æ˜¯å¦åˆé€‚
- æ£€ç´¢å‚æ•°æ˜¯å¦åˆç†
- æ•°æ®è´¨é‡æ˜¯å¦è¾¾æ ‡

### Q4: APIå“åº”æ…¢
**A:** è€ƒè™‘ï¼š
- å¼‚æ­¥æ‰§è¡Œè¯„ä¼°ä»»åŠ¡
- å‡å°‘æµ‹è¯•ç”¨ä¾‹æ•°é‡
- ä½¿ç”¨ç¼“å­˜æœºåˆ¶

## ğŸ“š æ›´å¤šèµ„æº

- **å®Œæ•´æ–‡æ¡£**: [README_RETRIEVER_EVAL.md](README_RETRIEVER_EVAL.md)
- **ç³»ç»Ÿæ€»ç»“**: [SUMMARY_æ£€ç´¢å™¨è¯„ä¼°ç³»ç»Ÿ.md](SUMMARY_æ£€ç´¢å™¨è¯„ä¼°ç³»ç»Ÿ.md)
- **APIæ–‡æ¡£**: http://localhost:8000/api/v1/docs
- **æµ‹è¯•è„šæœ¬**: [test_retriever_eval.py](test_retriever_eval.py)
- **ä½¿ç”¨ç¤ºä¾‹**: [example_t2ranking_usage.py](example_t2ranking_usage.py)

## ğŸ‰ å¼€å§‹ä½¿ç”¨

ç°åœ¨ä½ å·²ç»å‡†å¤‡å¥½å¼€å§‹ä½¿ç”¨æ£€ç´¢å™¨è¯„ä¼°ç³»ç»Ÿäº†ï¼

```bash
# 1. è¿è¡Œæµ‹è¯•éªŒè¯
python test_retriever_eval.py

# 2. æŸ¥çœ‹ç¤ºä¾‹
python example_t2ranking_usage.py

# 3. å¯åŠ¨APIæœåŠ¡
python run.py

# 4. å¼€å§‹è¯„ä¼°ä½ çš„æ£€ç´¢ç³»ç»Ÿï¼
```

**ç¥è¯„ä¼°é¡ºåˆ©ï¼** ğŸš€

