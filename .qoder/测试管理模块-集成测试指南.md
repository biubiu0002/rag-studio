# 测试管理模块 - 集成测试指南

## 概述

本文档提供新测试管理模块的集成测试步骤，包括后端API测试和前端界面测试。

## 一、后端API测试

### 1. 启动后端服务

```bash
cd /data/workspace/rag-studio/backend
# 确保虚拟环境已激活
source venv/bin/activate  # Linux/Mac
# 或
venv\Scripts\activate  # Windows

# 启动FastAPI服务
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 2. 运行API测试脚本

在新的终端窗口中：

```bash
cd /data/workspace/rag-studio/backend
python test_new_api.py
```

**预期结果**：
- ✅ 成功创建检索器测试用例
- ✅ 成功创建生成测试用例
- ✅ 成功查询测试用例列表
- ✅ 成功更新和删除测试用例
- ✅ 成功管理期望答案和上下文

### 3. 手动API测试（可选）

访问 Swagger UI：`http://localhost:8000/docs`

测试以下关键API：

#### 检索器测试用例
- `POST /api/v1/tests/retriever/cases` - 创建用例
- `GET /api/v1/tests/retriever/cases` - 列表查询
- `PUT /api/v1/tests/retriever/cases/{case_id}` - 更新用例
- `POST /api/v1/tests/retriever/cases/{case_id}/answers` - 添加期望答案
- `DELETE /api/v1/tests/retriever/cases/{case_id}` - 删除用例

#### 生成测试用例
- `POST /api/v1/tests/generation/cases` - 创建用例
- `GET /api/v1/tests/generation/cases` - 列表查询
- `PUT /api/v1/tests/generation/cases/{case_id}` - 更新用例
- `POST /api/v1/tests/generation/cases/{case_id}/contexts` - 添加上下文
- `DELETE /api/v1/tests/generation/cases/{case_id}` - 删除用例

## 二、前端界面测试

### 1. 启动前端开发服务器

```bash
cd /data/workspace/rag-studio/web
npm install  # 首次运行或依赖更新后
npm run dev
```

访问：`http://localhost:3000`

### 2. 测试步骤

#### 2.1 检索器测试用例管理

1. **导航到页面**
   - 点击侧边栏 "测试管理" → "检索器用例"
   - 验证：左侧显示测试集列表，右侧显示用例表格

2. **创建测试集（如果没有）**
   - 先进入 "测试集管理"
   - 创建类型为 "retrieval" 的测试集
   - 返回 "检索器用例" 页面

3. **创建测试用例**
   - 选择一个测试集
   - 点击 "新建用例" 按钮
   - 填写问题：`什么是机器学习？`
   - 添加期望答案：
     * 答案文本：`机器学习是人工智能的一个分支`
     * Chunk ID：可选
     * 关联度分数：1.0
   - 点击 "添加答案" 添加第二个答案
   - 填写元数据（可选）：`{"category": "ML"}`
   - 点击 "创建"
   - 验证：用例出现在表格中

4. **编辑测试用例**
   - 点击用例行的编辑按钮
   - 修改问题或答案
   - 调整关联度分数（0-1之间）
   - 点击 "保存"
   - 验证：修改已保存

5. **管理期望答案**
   - 在编辑对话框中
   - 点击 "添加答案" 按钮添加新答案
   - 点击 X 按钮删除答案（至少保留一个）
   - 验证：答案列表正确更新

6. **删除测试用例**
   - 点击删除按钮
   - 确认删除
   - 验证：用例从列表中移除

#### 2.2 生成测试用例管理

1. **导航到页面**
   - 点击侧边栏 "测试管理" → "生成用例"
   - 验证：左侧显示测试集列表，右侧显示用例表格

2. **创建测试集（如果没有）**
   - 先进入 "测试集管理"
   - 创建类型为 "generation" 的测试集
   - 返回 "生成用例" 页面

3. **创建测试用例**
   - 选择一个测试集
   - 点击 "新建用例" 按钮
   - 填写问题：`解释深度学习的基本原理`
   - 填写参考答案：`深度学习使用多层神经网络...`
   - 填写Ground Truth（可选）：标准答案
   - 添加上下文：
     * 上下文1：`神经网络是由多个神经元组成的...`
     * 点击 "添加上下文" 添加更多
   - 填写元数据（可选）
   - 点击 "创建"
   - 验证：用例出现在表格中

4. **编辑测试用例**
   - 点击编辑按钮
   - 修改问题、答案或上下文
   - 点击 "保存"
   - 验证：修改已保存

5. **管理上下文**
   - 在编辑对话框中
   - 点击 "添加上下文" 按钮
   - 点击 X 按钮删除上下文
   - 验证：上下文列表正确更新

6. **删除测试用例**
   - 点击删除按钮
   - 确认删除
   - 验证：用例从列表中移除

## 三、数据验证

### 1. 检查数据持久化

检索器测试用例数据文件：
```bash
cat /data/workspace/rag-studio/backend/storage/retriever_test_cases.json
```

生成测试用例数据文件：
```bash
cat /data/workspace/rag-studio/backend/storage/generation_test_cases.json
```

### 2. 验证数据结构

**检索器测试用例示例**：
```json
{
  "id": "xxx",
  "test_set_id": "test-set-xxx",
  "question": "什么是机器学习？",
  "expected_answers": [
    {
      "answer_text": "机器学习是人工智能的一个分支",
      "chunk_id": "chunk-123",
      "relevance_score": 1.0
    }
  ],
  "metadata": {"category": "ML"},
  "created_at": "2024-xx-xx...",
  "updated_at": "2024-xx-xx..."
}
```

**生成测试用例示例**：
```json
{
  "id": "xxx",
  "test_set_id": "test-set-xxx",
  "question": "解释深度学习的基本原理",
  "reference_answer": {
    "answer_text": "深度学习使用多层神经网络...",
    "ground_truth": "标准答案..."
  },
  "contexts": [
    "神经网络是由多个神经元组成的..."
  ],
  "metadata": {},
  "created_at": "2024-xx-xx...",
  "updated_at": "2024-xx-xx..."
}
```

## 四、常见问题排查

### 问题1：后端API返回404

**解决方案**：
- 确认路由已注册：检查 `app/main.py` 中是否包含：
  ```python
  app.include_router(retriever_router, prefix="/api/v1")
  app.include_router(generation_router, prefix="/api/v1")
  ```
- 重启后端服务

### 问题2：前端界面空白

**解决方案**：
- 检查浏览器控制台是否有JavaScript错误
- 确认导航配置正确
- 检查API调用是否成功（Network面板）

### 问题3：创建用例失败

**解决方案**：
- 检查必填字段是否已填写
- 验证JSON格式（元数据字段）
- 检查关联度分数是否在0-1之间
- 确认至少有一个期望答案

### 问题4：数据不显示

**解决方案**：
- 确认测试集已选择
- 检查后端服务是否运行
- 查看浏览器控制台和Network面板
- 检查API响应数据格式

## 五、性能测试（可选）

### 1. 批量创建测试

```python
import requests

# 批量创建检索器测试用例
cases = [
    {
        "test_set_id": "your-test-set-id",
        "question": f"测试问题 {i}",
        "expected_answers": [
            {
                "answer_text": f"答案 {i}",
                "relevance_score": 1.0
            }
        ]
    }
    for i in range(100)
]

response = requests.post(
    "http://localhost:8000/api/v1/tests/retriever/cases/batch",
    json={"cases": cases}
)
print(response.json())
```

### 2. 分页测试

测试大量数据的分页加载：
- 创建100+条测试用例
- 在前端界面测试分页功能
- 验证翻页性能和数据正确性

## 六、回归测试

确保新模块不影响现有功能：

1. **旧版测试用例管理**
   - 访问 "旧版用例管理" 页面
   - 验证功能正常

2. **检索器评估**
   - 使用新创建的测试用例
   - 执行检索器评估
   - 验证评估结果

3. **生成器评估**
   - 使用新创建的测试用例
   - 执行RAGAS评估
   - 验证评估结果

## 七、成功标准

所有以下测试通过即认为集成成功：

- ✅ 后端API全部正常响应
- ✅ 前端界面正常渲染
- ✅ 可以创建、编辑、删除测试用例
- ✅ 期望答案/上下文管理正常
- ✅ 数据持久化正确
- ✅ 分页功能正常
- ✅ 左侧sidebar和右侧内容正确交互
- ✅ 表格展示清晰易用
- ✅ 无JavaScript错误
- ✅ 不影响现有功能

## 八、后续优化建议

1. **批量导入功能**
   - 支持CSV/JSON文件导入
   - 提供模板下载

2. **批量编辑**
   - 批量修改关联度分数
   - 批量添加元数据

3. **搜索过滤**
   - 按问题内容搜索
   - 按关联度分数过滤

4. **导出功能**
   - 导出为JSON/CSV格式
   - 用于数据备份和分享

5. **验证增强**
   - 实时表单验证
   - 更友好的错误提示

6. **性能优化**
   - 虚拟滚动（大数据量）
   - 懒加载优化
